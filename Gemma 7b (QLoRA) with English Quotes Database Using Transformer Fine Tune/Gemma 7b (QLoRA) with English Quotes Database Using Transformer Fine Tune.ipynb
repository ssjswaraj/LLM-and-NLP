{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11384,"sourceType":"modelInstanceVersion","modelInstanceId":6216},{"sourceId":11413,"sourceType":"modelInstanceVersion","modelInstanceId":6206}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-22T04:41:22.885199Z","iopub.execute_input":"2024-06-22T04:41:22.885598Z","iopub.status.idle":"2024-06-22T04:41:24.805483Z","shell.execute_reply.started":"2024-06-22T04:41:22.885568Z","shell.execute_reply":"2024-06-22T04:41:24.804464Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# !pip install --upgrade pyarrow\n# !pip3 install -q -U pyarrow","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:41:24.807124Z","iopub.execute_input":"2024-06-22T04:41:24.807589Z","iopub.status.idle":"2024-06-22T04:41:24.811615Z","shell.execute_reply.started":"2024-06-22T04:41:24.807560Z","shell.execute_reply":"2024-06-22T04:41:24.810589Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# !pip3 install -q -U bitsandbytes\n# !pip3 install -q -U peft\n# !pip3 install -q -U trl\n# !pip3 install -q -U accelerate\n# !pip3 install -q -U datasets\n# !pip3 install -q -U transformers","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:41:24.812682Z","iopub.execute_input":"2024-06-22T04:41:24.812910Z","iopub.status.idle":"2024-06-22T04:41:24.823252Z","shell.execute_reply.started":"2024-06-22T04:41:24.812889Z","shell.execute_reply":"2024-06-22T04:41:24.822581Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip3 install -q -U bitsandbytes==0.42.0\n!pip3 install -q -U peft==0.8.2\n!pip3 install -q -U trl==0.7.10\n!pip3 install -q -U accelerate==0.27.1\n!pip3 install -q -U transformers==4.38.0\n!pip3 install -q -U datasets==2.17.0","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:41:24.825516Z","iopub.execute_input":"2024-06-22T04:41:24.825791Z","iopub.status.idle":"2024-06-22T04:43:06.646799Z","shell.execute_reply.started":"2024-06-22T04:41:24.825767Z","shell.execute_reply":"2024-06-22T04:43:06.645672Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\ngcsfs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2023.10.0 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\ns3fs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport transformers\nimport torch\n# from google.colab import userdata\n# from datasets import load_dataset\n\nfrom trl import SFTTrainer\nfrom peft import LoraConfig\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers import BitsAndBytesConfig, GemmaTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:43:06.648215Z","iopub.execute_input":"2024-06-22T04:43:06.648561Z","iopub.status.idle":"2024-06-22T04:43:34.913283Z","shell.execute_reply.started":"2024-06-22T04:43:06.648528Z","shell.execute_reply":"2024-06-22T04:43:34.912349Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-06-22 04:43:21.402015: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-22 04:43:21.402151: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-22 04:43:21.686919: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Quantization**","metadata":{}},{"cell_type":"code","source":"model_id = \"/kaggle/input/gemma/transformers/7b/2\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:43:34.914816Z","iopub.execute_input":"2024-06-22T04:43:34.915465Z","iopub.status.idle":"2024-06-22T04:43:34.921240Z","shell.execute_reply.started":"2024-06-22T04:43:34.915429Z","shell.execute_reply":"2024-06-22T04:43:34.920316Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id,\n                                             quantization_config=bnb_config,\n                                             device_map={\"\":0})","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:43:34.922324Z","iopub.execute_input":"2024-06-22T04:43:34.922653Z","iopub.status.idle":"2024-06-22T04:45:42.361664Z","shell.execute_reply.started":"2024-06-22T04:43:34.922629Z","shell.execute_reply":"2024-06-22T04:45:42.360892Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52b2b54418084a6d85d4c3ae89409fcf"}},"metadata":{}}]},{"cell_type":"markdown","source":"**Inference before fine tuning**","metadata":{}},{"cell_type":"code","source":"text = \"Quote: Imagination is more,\"\ndevice = \"cuda:0\"\ninputs = tokenizer(text, return_tensors=\"pt\").to(device)\n\noutputs = model.generate(**inputs, max_new_tokens=20)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:45:42.363061Z","iopub.execute_input":"2024-06-22T04:45:42.363357Z","iopub.status.idle":"2024-06-22T04:45:47.968933Z","shell.execute_reply.started":"2024-06-22T04:45:42.363332Z","shell.execute_reply":"2024-06-22T04:45:47.967937Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Quote: Imagination is more, more important than knowledge.\n\nAlbert Einstein\n\nThe world is a place of wonder and imagination. It\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"Quote: Imagination is more\"\ndevice = \"cuda:0\"\ninputs = tokenizer(text, return_tensors=\"pt\").to(device)\n\noutputs = model.generate(**inputs, max_new_tokens=20)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:45:47.970043Z","iopub.execute_input":"2024-06-22T04:45:47.970300Z","iopub.status.idle":"2024-06-22T04:45:50.336544Z","shell.execute_reply.started":"2024-06-22T04:45:47.970277Z","shell.execute_reply":"2024-06-22T04:45:50.335624Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Quote: Imagination is more important than knowledge.\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"false\"\nos.environ[\"WANDB_MODE\"] = \"dryrun\"","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:45:50.339792Z","iopub.execute_input":"2024-06-22T04:45:50.340061Z","iopub.status.idle":"2024-06-22T04:45:50.344174Z","shell.execute_reply.started":"2024-06-22T04:45:50.340037Z","shell.execute_reply":"2024-06-22T04:45:50.343238Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**dataset**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndata = load_dataset(\"Abirate/english_quotes\")\ndata = data.map(lambda samples: tokenizer(samples[\"quote\"]), batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:45:50.345234Z","iopub.execute_input":"2024-06-22T04:45:50.345521Z","iopub.status.idle":"2024-06-22T04:45:53.115964Z","shell.execute_reply.started":"2024-06-22T04:45:50.345496Z","shell.execute_reply":"2024-06-22T04:45:53.114982Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7228f7160b564456bd3ac5884a92a2d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/647k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef88f8c19d4d4940a0040dae0e745120"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5cbdfd6e40e4956bd4f2fb4ccb8f8e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2508 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"856bba1ecbe942758613f7b144f75375"}},"metadata":{}}]},{"cell_type":"code","source":"print(data['train'])","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:45:53.117116Z","iopub.execute_input":"2024-06-22T04:45:53.117440Z","iopub.status.idle":"2024-06-22T04:45:53.122165Z","shell.execute_reply.started":"2024-06-22T04:45:53.117404Z","shell.execute_reply":"2024-06-22T04:45:53.121323Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['quote', 'author', 'tags', 'input_ids', 'attention_mask'],\n    num_rows: 2508\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"data['train']['quote'][0:3]","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:45:53.123377Z","iopub.execute_input":"2024-06-22T04:45:53.123724Z","iopub.status.idle":"2024-06-22T04:45:53.146296Z","shell.execute_reply.started":"2024-06-22T04:45:53.123692Z","shell.execute_reply":"2024-06-22T04:45:53.144171Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['“Be yourself; everyone else is already taken.”',\n \"“I'm selfish, impatient and a little insecure. I make mistakes, I am out of control and at times hard to handle. But if you can't handle me at my worst, then you sure as hell don't deserve me at my best.”\",\n \"“Two things are infinite: the universe and human stupidity; and I'm not sure about the universe.”\"]"},"metadata":{}}]},{"cell_type":"code","source":"def formatting_func(example):\n    text = f\"Quote: {example['quote'][0]}\\nAuthor: {example['author'][0]}\"\n    return [text]","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:45:53.147610Z","iopub.execute_input":"2024-06-22T04:45:53.148766Z","iopub.status.idle":"2024-06-22T04:45:53.156154Z","shell.execute_reply.started":"2024-06-22T04:45:53.148707Z","shell.execute_reply":"2024-06-22T04:45:53.155232Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**LoRA Configuration**","metadata":{}},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r = 8,\n    target_modules = [\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n    task_type = \"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:45:53.157317Z","iopub.execute_input":"2024-06-22T04:45:53.157931Z","iopub.status.idle":"2024-06-22T04:45:53.168012Z","shell.execute_reply.started":"2024-06-22T04:45:53.157893Z","shell.execute_reply":"2024-06-22T04:45:53.167079Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**Finetuning**","metadata":{}},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=data[\"train\"],\n    args=transformers.TrainingArguments(\n        per_device_train_batch_size=1,\n        gradient_accumulation_steps=4,\n        warmup_steps=2,\n        max_steps=100,\n        learning_rate=2e-4,\n        fp16=True,\n        logging_steps=1,\n        output_dir=\"outputs\",\n        optim=\"paged_adamw_8bit\"\n    ),\n    peft_config=lora_config,\n    formatting_func=formatting_func,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:45:53.169197Z","iopub.execute_input":"2024-06-22T04:45:53.170015Z","iopub.status.idle":"2024-06-22T04:45:55.067784Z","shell.execute_reply.started":"2024-06-22T04:45:53.169966Z","shell.execute_reply":"2024-06-22T04:45:55.066916Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:223: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2508 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5fbe4176a284347b740ee83cdd05c96"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:290: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:45:55.074224Z","iopub.execute_input":"2024-06-22T04:45:55.074512Z","iopub.status.idle":"2024-06-22T04:56:01.519614Z","shell.execute_reply.started":"2024-06-22T04:45:55.074487Z","shell.execute_reply":"2024-06-22T04:56:01.518375Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [100/100 09:39, Epoch 100/100]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.916800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4.527300</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.955400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.671400</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.462900</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.380600</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.319200</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.286600</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.330400</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.410000</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.295600</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.240200</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.228500</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.194400</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.146300</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.104600</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.082800</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.036700</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.028200</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.027100</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.029200</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.025600</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.030900</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.024600</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.027800</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.024700</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.030600</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.030400</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.046300</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.038200</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.033400</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.026000</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.025600</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.028800</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.024000</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.030300</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.023800</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.026000</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.033700</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.025000</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.030000</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.025800</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.024900</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.037400</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.031900</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.029900</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.024500</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.027100</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.026600</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.027500</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.036800</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.033000</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>0.028900</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.025800</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.031100</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.024900</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>0.025000</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.031000</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>0.027800</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.025800</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>0.025800</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.026000</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>0.029600</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>0.029600</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.028100</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.026400</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>0.029100</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.026600</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.025200</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.024500</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.029800</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.032200</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.035500</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.033200</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.024200</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.024100</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.026000</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.025200</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.027900</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.024800</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.024600</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.024400</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.025500</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.024300</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.026100</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.027200</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.026000</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.024100</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.026100</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.025800</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.027500</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.024300</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.025400</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.024100</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.024500</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.024400</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.024400</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.027900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=100, training_loss=0.13866755479946732, metrics={'train_runtime': 606.0777, 'train_samples_per_second': 1.32, 'train_steps_per_second': 0.165, 'total_flos': 357069887907840.0, 'train_loss': 0.13866755479946732, 'epoch': 100.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"**Inference after fine tuning**","metadata":{}},{"cell_type":"code","source":"text = \"Quote: A woman is like a tea bag;\"\ndevice = \"cuda:0\"\ninputs = tokenizer(text, return_tensors=\"pt\").to(device)\n\noutputs = model.generate(**inputs, max_new_tokens=20)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:56:01.520869Z","iopub.execute_input":"2024-06-22T04:56:01.521167Z","iopub.status.idle":"2024-06-22T04:56:04.729997Z","shell.execute_reply.started":"2024-06-22T04:56:01.521142Z","shell.execute_reply":"2024-06-22T04:56:04.728974Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Quote: A woman is like a tea bag; the most wasted of all beverages.\nAuthor: Oscar Wilde\nThe most wasted of all beverages\n\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"Quote: Outside of a dog, a book is man's\"\ndevice = \"cuda:0\"\ninputs = tokenizer(text, return_tensors=\"pt\").to(device)\n\noutputs = model.generate(**inputs, max_new_tokens=20)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:56:04.731227Z","iopub.execute_input":"2024-06-22T04:56:04.731538Z","iopub.status.idle":"2024-06-22T04:56:07.863795Z","shell.execute_reply.started":"2024-06-22T04:56:04.731512Z","shell.execute_reply":"2024-06-22T04:56:07.862649Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Quote: Outside of a dog, a book is man's best friend.\nAuthor: Oscar Wilde\nThe most wasted of all days is one without laughter.\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"Quote: Imagination is more\"\ndevice = \"cuda:0\"\ninputs = tokenizer(text, return_tensors=\"pt\").to(device)\n\noutputs = model.generate(**inputs, max_new_tokens=30)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-06-22T04:56:07.865229Z","iopub.execute_input":"2024-06-22T04:56:07.865660Z","iopub.status.idle":"2024-06-22T04:56:12.255496Z","shell.execute_reply.started":"2024-06-22T04:56:07.865620Z","shell.execute_reply":"2024-06-22T04:56:12.253924Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Quote: Imagination is more important than knowledge.\nAuthor: Albert Einstein\nThe most wasted of all days is one without laughter.\nNicolas Chamfort\nThe most wasted of\n","output_type":"stream"}]}]}